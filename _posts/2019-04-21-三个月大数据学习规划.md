layout:     post
title:      大数据学习路径
subtitle:   规划 大数据 路线
date:       2019-04-21
author:     Gavin
header-img: img/post-bg-desk.jpg
catalog: true
tags:
    - 日记

```
信息来自GitChat博客:<https://blog.csdn.net/GitChat/article/details/78341484>
```

【不要错过文末彩蛋】

**申明：**

本文旨在为普通程序员（Java程序员最佳）提供一个入门级别的大数据技术学习路径，不适用于大数据工程师的进阶学习，也不适用于零编程基础的同学。

**前言：**

- 一、背景介绍
- 二、大数据介绍

**正文：**

一、大数据相关的工作介绍

二、大数据工程师的技能要求

三、大数据学习规划

四、持续学习资源推荐（书籍，博客，网站）

五、项目案例分析（批处理+实时处理）

## 前言

一、背景介绍
本人目前是一名大数据工程师，项目数据50T，日均数据增长20G左右，个人是从Java后端开发，经过3个月的业余自学成功转型大数据工程师。

二、大数据介绍
大数据本质也是数据，但是又有了新的特征，包括数据来源广、数据格式多样化（结构化数据、非结构化数据、Excel文件、文本文件等）、数据量大（最少也是TB级别的、甚至可能是PB级别）、数据增长速度快等。

针对以上主要的4个特征我们需要考虑以下问题：

1. 数据来源广，该如何采集汇总？，对应出现了Sqoop，Cammel，Datax等工具。

2. 数据采集之后，该如何存储？，对应出现了GFS，HDFS，TFS等分布式文件存储系统。

3. 由于数据增长速度快，数据存储就必须可以水平扩展。

4. 数据存储之后，该如何通过运算快速转化成一致的格式，该如何快速运算出自己想要的结果？

   对应的MapReduce这样的分布式运算框架解决了这个问题；但是写MapReduce需要Java代码量很大，所以出现了Hive，Pig等将SQL转化成MapReduce的解析引擎；

   普通的MapReduce处理数据只能一批一批地处理，时间延迟太长，为了实现每输入一条数据就能得到结果，于是出现了Storm/JStorm这样的低时延的流式计算框架；

   但是如果同时需要批处理和流处理，按照如上就得搭两个集群，Hadoop集群（包括HDFS+MapReduce+Yarn）和Storm集群，不易于管理，所以出现了Spark这样的一站式的计算框架，既可以进行批处理，又可以进行流处理（实质上是微批处理）.

5. 而后Lambda架构，Kappa架构的出现，又提供了一种业务处理的通用架构。

6. 为了提高工作效率，加快运速度，出现了一些辅助工具：

   - Ozzie，azkaban：定时任务调度的工具。
   - Hue，Zepplin：图形化任务执行管理，结果查看工具。
   - Scala语言：编写Spark程序的最佳语言，当然也可以选择用Python。
   - Python语言：编写一些脚本时会用到。
   - Allluxio，Kylin等：通过对存储的数据进行预处理，加快运算速度的工具。

### 正文

#### 一、大数据相关工作介绍

大数据方向的工作目前主要分为三个主要方向:

1. 大数据工程师
2. 数据分析师
3. 大数据科学家
4. 其他（数据挖掘等）

大数据方向的工作目前主要分为三个主要方向:

1. 大数据工程师
2. 数据分析师
3. 大数据科学家
4. 其他（数据挖掘等）

![img](http://images.gitbook.cn/a8ea12c0-ad9e-11e7-bc4e-bd9737349028)

**必须掌握的技能11条**

1. Java高级(虚拟机、并发)
2. Linux 基本操作
3. Hadoop（HDFS+MapReduce+Yarn ）
4. HBase（JavaAPI操作+Phoenix ）
5. Hive(Hql基本操作和原理理解）
6. Kafka
7. Storm/JStorm
8. Scala
9. Python
10. Spark (Core+sparksql+Spark streaming ）
11. 辅助小工具(Sqoop/Flume/Oozie/Hue等)

 **高阶技能6条**

1. 机器学习算法以及mahout库加MLlib
2. R语言
3. Lambda 架构
4. Kappa架构
5. Kylin
6. Alluxio

#### 三、学习路径

假设每天可以抽出3个小时的有效学习时间，加上周末每天保证10个小时的有效学习时间；

3个月会有（21*3+4*2*10）*3=**423**小时的学习时间。

**第一阶段（基础阶段）**

1）Linux学习（跟鸟哥学就ok了）—–20小时

1. Linux操作系统介绍与安装。
2. Linux常用命令。
3. Linux常用软件安装。
4. Linux网络。
5. 防火墙。
6. Shell编程等。

> 官网：<https://www.centos.org/download/>  
>
> 中文社区：<http://www.linuxidc.com/Linux/2017-09/146919.htm>

2）Java 高级学习（《深入理解Java虚拟机》、《Java高并发实战》）—30小时

1. 掌握多线程。
2. 掌握并发包下的队列。
3. 了解JMS。
4. 掌握JVM技术。
5. 掌握反射和动态代理。

> 官网：<https://www.java.com/zh_CN/> 
> 中文社区：<http://www.java-cn.com/index.html>

 3）Zookeeper学习

1. Zookeeper分布式协调服务介绍。
2. Zookeeper集群的安装部署.
3. Zookeeper数据结构、命令。
4. Zookeeper的原理以及选举机制。

（可以参照这篇博客进行学习：http://www.cnblogs.com/wuxl360/p/5817471.html）

> 官网：<http://zookeeper.apache.org/>  
>
> 中文社区：<http://www.aboutyun.com/forum-149-1.html>

第二阶段（攻坚阶段）

4）Hadoop （《Hadoop 权威指南》）—80小时

1. HDFS
   1. HDFS的概念和特性。
   2. HDFS的shell操作。
   3. HDFS的工作机制。
   4. HDFS的Java应用开发。
   5. MapReduce
2. MapReduce
   1. 运行WordCount示例程序。
   2. 了解MapReduce内部的运行机制。
      1. MapReduce程序运行流程解析。
      2. MapTask并发数的决定机制。
      3. MapReduce中的combiner组件应用。
      4. MapReduce中的序列化框架及应用。
      5. MapReduce中的排序。
      6. MapReduce中的自定义分区实现。
      7. MapReduce的shuffle机制。
      8. MapReduce利用数据压缩进行优化。
      9. MapReduce程序与YARN之间的关系。
      10. MapReduce参数优化。
3. MapReduce的Java应用开发

> 官网：<http://hadoop.apache.org/>  
>
> 中文文档：<http://hadoop.apache.org/docs/r1.0.4/cn/> 
>
>  中文社区：<http://www.aboutyun.com/forum-143-1.html>

5）Hive（《Hive开发指南》）–20小时

1. Hive 基本概念
   - Hive 应用场景。
   - Hive 与hadoop的关系。
   - Hive 与传统数据库对比。
   - Hive 的数据存储机制。
2. Hive 基本操作
   - Hive 中的DDL操作。
   - 在Hive 中如何实现高效的JOIN查询。
   - Hive 的内置函数应用。
   - Hive shell的高级使用方式。
   - Hive 常用参数配置。
   - Hive 自定义函数和Transform的使用技巧。
   - Hive UDF/UDAF开发实例。
3. Hive 执行过程分析及优化策略

> 官网：<https://hive.apache.org/>  
>
> 中文入门文档：<http://www.aboutyun.com/thread-11873-1-1.html>
>
> 中文社区：<http://www.aboutyun.com/thread-7598-1-1.html>

6）HBase（《HBase权威指南》）—20小时

1. hbase简介。
2. habse安装。
3. hbase数据模型。
4. hbase命令。
5. hbase开发。
6. hbase原理。

> 官网：<http://hbase.apache.org/> 
> 中文文档：<http://abloz.com/hbase/book.html> 
> 中文社区：<http://www.aboutyun.com/forum-142-1.html>

7）Scala（《快学Scala》）–20小时

1. Scala概述。
2. Scala编译器安装。
3. Scala基础。
4. 数组、映射、元组、集合。
5. 类、对象、继承、特质。
6. 模式匹配和样例类。
7. 了解Scala Actor并发编程。
8. 理解Akka。
9. 理解Scala高阶函数。

> 官网：<http://www.scala-lang.org/>  初级中文教程：<http://www.runoob.com/scala/scala-tutorial.html>

8）Spark （《Spark 权威指南》）—60小时

![enter image description here](http://images.gitbook.cn/e3202560-adda-11e7-8d75-f14e65a1bc39)

​	

1. Spark core

   - Spark概述。
   - Spark集群安装。
   - 执行第一个Spark案例程序（求PI）。

2. RDD

   ![enter image description here](http://images.gitbook.cn/02ffd320-addc-11e7-9923-17951b2031c1)

   - RDD概述。
   - 创建RDD。
   - RDD编程API（Transformation 和 Action Operations）。
   - RDD的依赖关系
   - RDD的缓存
   - DAG（有向无环图）

3. Spark SQL and DataFrame/DataSet

   ![enter image description here](http://images.gitbook.cn/9e06fa70-addb-11e7-9923-17951b2031c1)

   1. 1. - Spark SQL概述。
         - DataFrames。
         - DataFrame常用操作。
         - 编写Spark SQL查询程序。

4. Spark Streaming

   ![enter image description here](http://images.gitbook.cn/4c92ed70-addb-11e7-8d75-f14e65a1bc39)

   1. - park Streaming概述。
      - 理解DStream。
      - DStream相关操作（Transformations 和 Output Operations）。

5. Structured Streaming

6. 其他（MLlib and GraphX ）

**这个部分一般工作中如果不是数据挖掘，机器学习一般用不到，可以等到需要用到的时候再深入学习**

9）Python (推荐廖雪峰的博客—30小时

10）自己用虚拟机搭建一个集群，把所有工具都装上，自己开发一个小demo —30小时

​	可以自己用VMware搭建4台虚拟机，然后安装以上软件，搭建一个小集群（本人亲测，			I7，64位，16G内存，完全可以运行起来，以下附上我学习时用虚拟机搭建集群的操作文档)

**五、项目案例分析**
**1）点击流日志项目分析（此处借鉴CSDN博主的文章，由于没有授权，所以就没有贴过来，下面附上链接）—-批处理**

**http://blog.csdn.net/u014033218/article/details/76847263**

2）Spark Streaming在京东的项目实战（京东的实战案例值得好好研究一下，由于没有授权，所以就没有贴过来，下面附上链接）—实时处理 

**http://download.csdn.net/download/csdndataid_123/8079233**



集群搭建文档1.0版本

**1. 集群规划**

​	![enter image description here](http://images.gitbook.cn/2757ab40-adcc-11e7-9c1d-d1d3a666bff7)

​	所有需要用到的软件：

​	链接：<http://pan.baidu.com/s/1jIlAz2Y> 
	密码：kyxl

**2. 前期准备**

- [ ] ```
  2.0 系统安装
  
  2.1 主机名配置
  
  ​```
  2.1.0 vi /etc/sysconfig/network
      NETWORKING=yes
  
  2.1.1 vi /etc/sysconfig/network
      NETWORKING=yes
      HOSTNAME=ys02
  
  2.1.2 vi /etc/sysconfig/network
      NETWORKING=yes
  
  2.1.3 vi /etc/sysconfig/network
      NETWORKING=yes
      HOSTNAME=ys04
  ​```
  
  2.2 host文件修改
      2.2.0 vi /etc/hosts
          10.1.1.149 ys01
          10.1.1.148 ys02
          10.1.1.146 ys03
          10.1.1.145 ys04
  2.3 关闭防火墙(centos 7默认使用的是firewall，centos 6 默认是iptables)
  
  ​```
  2.3.0 systemctl stop firewalld.service （停止firewall）
  
  2.3.1 systemctl disable firewalld.service （禁止firewall开机启动）
  
  2.3.2 firewall-cmd --state （查看默认防火墙状态（关闭后显示notrunning，开启后显示running）
  ​```
  
  2.4 免密登录(ys01 ->ys02,03,04)
      ssh-keygen -t rsa
      ssh-copy-id ys02(随后输入密码)
      ssh-copy-id ys03（随后输入密码）
      ssh-copy-id ys04（随后输入密码）
      ssh ys02(测试是否成功)
      ssh ys03(测试是否成功)
      ssh ys04(测试是否成功)
  
  2.5 系统时区与时间同步
  
  - tzselect（生成日期文件）
  - cp /usr/share/zoneinfo/Asia/Shanghai  /etc/localtime（将日期文件copy到本地时间中）
  ```

  **3. 软件安装**

  ​	3.0 安装目录规划（软件为所有用户公用）

      3.0.0所有软件的安装放到/usr/local/ys/soft目录下(mkdir /usr/local/ys/soft)
      
      3.0.1所有软件安装到/usr/local/ys/app目录下(mkdir /usr/local/ys/app)

   	3.1 JDK（jdk1.7）安装

      3.1.1 alt+p 后出现sftp窗口，cd /usr/local/ys/soft，使用sftp上传tar包到虚机ys01的/usr/local/ys/soft目录下
      
      3.1.2解压jdk
        cd /usr/local/ys/soft
          #解压
          tar -zxvf jdk-7u80-linux-x64.tar.gz -C /usr/local/ys/app
      
      3.1.3将java添加到环境变量中
      vim /etc/profile
      #在文件最后添加
      export JAVA_HOME= /usr/local/ys/app/ jdk-7u80
      export PATH=$PATH:$JAVA_HOME/bin
      
      3.1.4 刷新配置
      source /etc/profile

  ​	3.2 Zookeeper安装

      3.2.0解压
      tar -zxvf zookeeper-3.4.5.tar.gz -C /usr/local/ys/app（解压）
      
      3.2.1 重命名
      mv zookeeper-3.4.5 zookeeper（重命名文件夹zookeeper-3.4.5为zookeeper）
      
      3.2.2修改环境变量
      vi /etc/profile(修改文件)
      添加内容：
      export ZOOKEEPER_HOME=/usr/local/ys/app/zookeeper
      export PATH=$PATH:$ZOOKEEPER_HOME/bin
      
      3.2.3 重新编译文件：
      source /etc/profile
      注意：3台zookeeper都需要修改
      
      3.2.4修改配置文件
      cd zookeeper/conf
      cp zoo_sample.cfg zoo.cfg
      vi zoo.cfg
      添加内容：
      dataDir=/usr/local/ys/app/zookeeper/data
      dataLogDir=/usr/local/ys/app/zookeeper/log
      server.1=ys01:2888:3888 (主机名, 心跳端口、数据端口)
      server.2=ys02:2888:3888
      server.3=ys04:2888:3888
      
      3.2.5 创建文件夹
      cd /usr/local/ys/app/zookeeper/
      mkdir -m 755 data
      mkdir -m 755 log
      
      3.2.6 在data文件夹下新建myid文件，myid的文件内容为：
      cd data
      vi myid
      添加内容：
          1
      将集群下发到其他机器上
      scp -r /usr/local/ys/app/zookeeper ys02:/usr/local/ys/app/
      scp -r /usr/local/ys/app/zookeeper ys04:/usr/local/ys/app/
      
      3.2.7修改其他机器的配置文件
      到ys02上：修改myid为：2
      到ys02上：修改myid为：3
      
      3.2.8启动（每台机器）
      zkServer.sh start
      查看集群状态
      jps（查看进程）
      zkServer.sh status（查看集群状态，主从信息）

  ​	3.3 Hadoop（HDFS+Yarn）

      3.3.0 alt+p 后出现sftp窗口，使用sftp上传tar包到虚机ys01的/usr/local/ys/soft目录下
      
      3.3.1 解压jdk
        cd /usr/local/ys/soft
          #解压
          tar -zxvf cenos-7-hadoop-2.6.4.tar.gz -C /usr/local/ys/app
      
      3.3.2 修改配置文件
      core-site.xml

  

![enter image description here](http://images.gitbook.cn/6fbf4440-add3-11e7-a143-bbd5157416e7)

`hdfs-site.xml`

![enter image description here](http://images.gitbook.cn/891726b0-add3-11e7-9c1d-d1d3a666bff7)

![enter image description here](http://images.gitbook.cn/91835ee0-add3-11e7-9c1d-d1d3a666bff7)

![enter image description here](http://images.gitbook.cn/9b2fdf40-add3-11e7-bb75-375e512bebfc)

![enter image description here](http://images.gitbook.cn/a232ea80-add3-11e7-bf6d-abf8194ef877)

![enter image description here](http://images.gitbook.cn/a951bb20-add3-11e7-a143-bbd5157416e7)

`yarn-sifite.xml`

![enter image description here](http://images.gitbook.cn/f1ce66f0-add3-11e7-bf6d-abf8194ef877)

svales

ys02
ys03
ys04

3.3.3集群启动（严格按照下面的步骤）
    3.3.3.1启动zookeeper集群（分别在ys01、ys02、ys04上启动zk）
        cd /usr/local/ys/app/zookeeper-3.4.5/bin/
        ./zkServer.sh start
        #查看状态：一个leader，两个follower
        ./zkServer.sh status

    3.3.3.2启动journalnode（分别在在mini5、mini6、mini7上执行）
        cd /usr/local/ys/app/hadoop-2.6.4
        sbin/hadoop-daemon.sh start journalnode
        #运行jps命令检验，ys02、ys03、ys04上多了JournalNode进程
    
    3.3.3.3格式化HDFS
        #在ys01上执行命令:
        hdfs namenode -format
        #格式化后会在根据core-site.xml中的hadoop.tmp.dir配置生成个文件，这里我配置的是/usr/local/ys/app/hadoop-2.6.4/tmp，然后将/usr/local/ys/app/hadoop-2.6.4/tmp拷贝到ys02的/usr/local/ys/app/hadoop-2.6.4/下。
        scp -r tmp/ ys02:/usr/local/ys /app/hadoop-2.6.4/
        ##也可以这样，建议hdfs namenode -bootstrapStandby
    
    3.3.3.4格式化ZKFC(在ys01上执行一次即可)
        hdfs zkfc -formatZK
    
    3.3.3.5启动HDFS(在ys01上执行)
        sbin/start-dfs.sh
    
    3.3.3.6启动YARN
        sbin/start-yarn.sh

3.3MySQL-5.6安装
    略过

3.4 Hive

    3.4.1 alt+p 后出现sftp窗口，cd /usr/local/ys/soft，使用sftp上传tar包到虚机ys01的/usr/local/ys/soft目录下
    
    3.4.2解压
    cd /usr/local/ys/soft
tar -zxvf hive-0.9.0.tar.gz -C /usr/local/ys/app

    3.4.3 .配置hive
    
        3.4.3.1配置HIVE_HOME环境变量  vi conf/hive-env.sh 配置其中的$hadoop_home
    
        3.4.3.2配置元数据库信息   vi  hive-site.xml 
添加如下内容：

​	![enter image description here](http://images.gitbook.cn/624af100-add4-11e7-bb75-375e512bebfc)

​	![enter image description here](http://images.gitbook.cn/6c5c26a0-add4-11e7-bb75-375e512bebfc)

    3.4.4 安装hive和mysq完成后，将mysql的连接jar包拷贝到$HIVE_HOME/lib目录下
    如果出现没有权限的问题，在mysql授权(在安装mysql的机器上执行)
    mysql -uroot -p
    #(执行下面的语句  *.*:所有库下的所有表   %：任何IP地址或主机都可以连接)
    GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'root' WITH GRANT OPTION;
    FLUSH PRIVILEGES;
    
    3.4.5 Jline包版本不一致的问题，需要拷贝hive的lib目录中jline.2.12.jar的jar包替换掉hadoop中的 /usr/local/ys/app/hadoop-2.6.4/share/hadoop/yarn/lib/jline-0.9.94.jar
    
    3.4.6启动hive
    bin/hive

```
3.5 Kafka
    3.5.1 下载安装包
    http://kafka.apache.org/downloads.html
    在linux中使用wget命令下载安装包
    wget http://mirrors.hust.edu.cn/apache/kafka/0.8.2.2/kafka_2.11-0.8.2.2.tgz

  3.5.2 解压安装包
    tar -zxvf /usr/local/ys/soft/kafka_2.11-0.8.2.2.tgz -C /usr/local/ys/app/
cd /usr/local/ys/app/
ln -s kafka_2.11-0.8.2.2 kafka

  3.5.3 修改配置文件
    cp 
    /usr/local/ys/app/kafka/config/server.properties
   /usr/local/ys/app/kafka/config/server.properties.bak
    vi  /usr/local/ys/kafka/config/server.properties	
```

